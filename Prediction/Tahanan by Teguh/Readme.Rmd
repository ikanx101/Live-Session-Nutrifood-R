---
title: "Text prediction tahanan"
subtitle: "Training R Nutrifood"
author: "Teguh Prasetia"
date: "24 Agustus 2020"
output: 
  github_document:
    pandoc_args: --webtex
---

```{r setup, include=FALSE}
setwd("~/Documents/Training-R---Data-Viz/Prediction/Tahanan by Teguh")
knitr::opts_chunk$set(echo = TRUE)
```

# Pendahuluan

Salah satu data yang umum kita jumpai adalah data yang diinput berupa free text. Departemen QC NFI kadang melakukan penahanan bahan baku yang datang karena adanya ketidaksesuaian bahan terhadap spesifikasi untuk dievaluasi lebih lanjut oleh RD terkait. Alasan penahanan produk diinput berupa free text pada aplikasi QC online, kemudian RD akan melakukan evaluasi dan menjawab dalam bentuk free text juga.
Tujuan dari project ini adalah untuk :

1. Exploratory data analysis untuk mengetahui pola kejadian tahanan berdasarkan text alasan penahanan, khususnya pada BB yang ditolak, rilis bersyarat, maupun pada akhirnya diterima.
2. Melakukan uji coba membuat model prediktif untuk memprediksi apakah suatu bahan baku akan ditolak, release, atau release bersyarat berdasarkan data text alasan penahanan yang sudah diolah.

>(kelas silakan mulai mengerjakan dari line 244)

# Workflow

Load data -> merapikan freetext (menyeragamkan, menghapus kata-kata yang tidak perlu, dll) -> convert data menjadi tidytext -> explorasi karakter data dari masing-masing variabel target (dalam hal ini, pola2 kata yang sering muncul pada setiap target, dll) -> preparasi data untuk pembuatan model -> pembuatan model menggunakan decision tree dan naive bayes -> evaluasi masing-masing model.

# Setup library

Install package katadasaR jika belum ada, silakan hapus tanda # pada masing-masing line di chunk di bawah
```{r}
# install.packages("devtools")
# devtools::install_github("nurandi/katadasaR")
```

Load library yang dibutuhkan
```{r, message=FALSE, warning=FALSE}
library(readxl)
library(tidyverse)
library(tidytext)
library(tm)
library(SnowballC)
library(katadasaR)
library(textclean)
library(tokenizers)
library(stopwords)
library(ggplot2)
library(RVerbalExpressions)
library(widyr)
library(igraph)
library(ggraph)
library(caret)
library(partykit)
library(e1071)
```

# Load data dan explore data awal

Load data tahanan
```{r}
tahanan <- read_xlsx("Tahanan2.xlsx")
tahanan$Status <- as.factor(tahanan$Status)
```

Explore data frame dengan melihat beberapa data, summary data, dan keberadaan NA
```{r}
head(tahanan)
```

```{r}
summary(tahanan)
```
Diketahui bahwa data tahanan terdiri atas 3 kolom yaitu:
1. Alasan = alasan penahanan berupa freetext
2. Evaluasi = hasil evaluasi tahanan oleh RD berupa freetext
3. Status tahanan = keputusan tahanan yang terdiri atas 3 macam, yaitu :bersyarat, OK, dan tolak.


Melihat data apakah ada yang memiliki data NA dan menghapus data NA

```{r}
which(is.na(tahanan))
```

Berdasarkan tujuan project ini, kolom yang akan digunakan sebagai prediktor adalah alasan dan target variabelnya status. 
Karena ada data yang NA, maka diputuskan untuk tidak menggunakan data yang NA tersebut dengan menghapus baris yang berisi data NA.
```{r}
tahanan <- tahanan %>%
  mutate(No = 1:nrow(tahanan)) %>%
  select(No, Alasan, Status) %>%
  filter (!is.na(Alasan))
```

# Merapikan data text part 1. Normalisasi text : menghapus tanda baca, membuat jadi huruf kecil semua, menghapus angka.

Mendaftarkan kata-kata atau pola yang akan dinormalkan/dihapus
```{r}
stopwords <- read.csv("stopwords-id.txt", encoding = "UTF-8",header = F)
stopwords <- as.character(stopwords$V1)
punctuation <- rx_punctuation()
number <- rx_digit()
punctuation2 <- c("|", ">", "<", "|")
```


Melakukan normalisasi text menggunakan fungsi dari paket stringr
```{r}
tahanan$Alasan <- tahanan$Alasan %>%
  str_to_lower() %>%
  str_remove_all(pattern = punctuation) %>% 
  str_remove_all(pattern = number) %>%
  str_remove_all(pattern = "di ") %>%
  str_remove_all(pattern = "dan") %>%
  str_remove_all(pattern = "ok") %>%
  str_remove_all(pattern = "=") %>%
  str_remove_all(pattern = punctuation2) %>%
  str_squish()
```

Output normalisasi tahap 1
```{r}
head(tahanan)
```

Buat data dummy untuk uji korelasi antar kata pada setiap status
```{r}
tahanan.correl <- tahanan %>%
  mutate (Alasan = paste0(Alasan, " ", Status))
```



# Merapikan data text part 2. Normalisasi text : konversi menjadi format tidytext, konversi menjadi kata dasar, menghapus stopwords bahasa Indonesia.

Menghapus kata-kata yang belum bisa dihapus menggunakan stringr pada data tahanan (note: kata-kata pada dokumen stopwords tidak bisa dihapus langsung karena ukuran vector berbeda)
```{r}
tahanan.tidy <- tahanan %>%
  #select (-Status) %>%
  unnest_tokens(word, Alasan) %>%
  filter (!word %in% stopwords) %>%
  filter (!word %in% c("a","b","c","d","e","f", "hasil", "lebih","standar", "dibanbdingkan", "dibanding", "banding"))
```

```{r}
stemming <- function(x){
  paste(lapply(x,katadasar),collapse = " ")}
```

```{r}
tahanan.tidy$word <- lapply(tahanan.tidy$word, stemming)
tahanan.tidy$word <- as.character(tahanan.tidy$word)
```

```{r}
head(tahanan.tidy)
```

Menghapus kata-kata yang belum bisa dihapus menggunakan stringr pada data tahanan correl (note: kata-kata pada dokumen stopwords tidak bisa dihapus langsung karena ukuran vector berbeda)

```{r}
tahanan.tidy1 <- tahanan.correl %>%
  #select (-Status) %>%
  unnest_tokens(word, Alasan) %>%
  filter (!word %in% stopwords) %>%
  filter (!word %in% c("a","b","c","d","e","f", "hasil", "lebih", "standar", "dibanding", "dibanbdingkan", "banding"))
```

```{r}
tahanan.tidy1$word <- lapply(tahanan.tidy1$word, stemming)
tahanan.tidy1$word <- as.character(tahanan.tidy1$word)
```

```{r}
head(tahanan.tidy1)
```


# Eksplorasi data untuk melihat karakteristik kata-kata yang sering muncul pada berbagai keputusan tahanan

## Melihat Kata-kata yang sering muncul pada masing-masing status
```{r}
tahanan.tidy %>% 
  group_by(Status,word) %>%
  summarise(jumlah = n()) %>%
  arrange(jumlah) %>%
  top_n(20) %>%
  ungroup() %>%
  ggplot(aes(reorder(word, jumlah), jumlah))+
  geom_col(aes(fill=Status), position = "dodge") + 
  coord_flip() +
  labs(title = "Kata-kata umum pada masing-masing status", x = "Kata-kata umum", y = "jumlah")+
  facet_wrap(~Status, scales = "free") 
```

## Menghitung korelasi kata-kata tertentu pada masing-masing status dan menampilkannya pada bar chart dan peta korelasi
```{r}
correl <- tahanan.tidy1 %>%
  group_by(word) %>%
  pairwise_cor(word,No, sort = TRUE)
```

```{r}
correl %>%
  filter(item1 %in% c("ok", "syarat", "tolak")) %>%
  group_by(item1) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(item2 = reorder(item2,correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_col(aes(fill=item1), position = "dodge") +
  coord_flip()+
  facet_wrap(~item1, scales = "free")
```

```{r}

set.seed(200)

correl %>%
  filter(item1 %in% c("ok", "syarat", "tolak")) %>%
  filter(correlation > .15) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  labs(title = "Peta korelasi kata-kata untuk masing-masing status")+
  theme_void()
```

Berdasarkan visualisasi data yang dilakukan, diketahui terdapat kata-kata yang umum dan berkorelasi kuat terhadap status-status akhir suatu tahanan.

------------------------------------------------------------------------------------------------------------------------------------------------

# In class activity

1. Buat model decision tree menggunakan data test dan data train yang sudah disediakan (Line 365)

2. Jelaskan beberapa kelemahan model decision tree yang dibuat untuk memprediksi status tahanan pada data hasil prediksi data train maupun data test. (Line 377 dan Line 387). Mengapa kelemahan tersebut bisa terjadi? (bisa mengacu pada eksplorasi data di atas)

3. Bandingkan dengan metode naive bayes yang sudah disediakan. Yang manakah yang lebih bagus? Berdasarkan confusion matrix yang disediakan, jelaskan kemampuan model NB untuk memprediksi kelas `tolak` (Line 315 dan Line 381)

------------------------------------------------------------------------------------------------------------------------------------------------

# Pembuatan model

## Preparasi data

```{r}
data.model <- tahanan.tidy %>%
  group_by(No,word) %>%
  summarise(jumlah.kata = n()) %>%
  pivot_wider(names_from = word,values_from = jumlah.kata)

data.model[is.na(data.model)] <- 0
data.model$status <- tahanan$Status
head(data.model)
```
## Splitting data
```{r}
set.seed(999)
idx <- sample(nrow(data.model),nrow(data.model)*0.8)

train <- data.model [idx,-1]
test <- data.model[-idx,-1]
```



## Pembuatan model menggunakan naive bayes

Preparasi data
```{r}
bernoulli_conv <- function(x){
        x <- as.factor(ifelse(x > 0, 1, x))
}
```

```{r}
train.NB <- train %>%
  select(-status)
```

```{r}
test.NB <- test %>%
  select(-status)
```


```{r}
train.NB <- apply(X = train.NB ,MARGIN = 2,FUN = bernoulli_conv)
test.NB <- apply(X = test.NB ,MARGIN = 2,FUN = bernoulli_conv)
```


Pembuatan model
```{r}
model.NB <- naiveBayes(x =train.NB, y=train$status)
```

Memprediksi menggunakan naive bayes untuk data train
```{r}
predict.NB.train <- predict(object = model.NB, newdata = train.NB)
```

Evaluasi hasil prediksi fitted (terhadap data train)
```{r}
confusionMatrix(as.factor(predict.NB.train),as.factor(train$status))
```

Sensitivity (Jumlah kelas target yang dijawab dengan benar, dibagi total jumlah kelas target) = recall
```{r}
# Kelas bersyarat
198/(198+50+1)

# Kelas OK
241/(241+3+3)

# Kelas tolak
48/(48+9+0)
```

Spesifisitas (Jumlah kelas bukan target yang dijawab dengan benar, dibagi total jumlah kelas bukan target)
```{r}
#Kelas bersyarat
(241+9+3+48+0)/(241+9+3+48+3+0)

#Kelas OK 
(198+1+48+0)/(198+1+48+0+9+50)

#Kelas tolak
(198+3+50+241)/(198+3+50+241+1+3)
```

Pos pred value (Jumlah prediksi yang benar terhadap kelas target, dibagi total prediksi terhadap target tersebut) = precision (efficiency)
```{r}
# Tebakan kelas bersyarat
198/(198+3+0)

# Tebakan kelas OK
241/(241+50+9)

# Tebakan kelas tolak
48/(48+3+1)
```

Memprediksi data test
```{r}
predict.NB.test <- predict(object = model.NB, newdata = test.NB)
```

Evaluasi hasil prediksi data test
```{r}
confusionMatrix(as.factor(predict.NB.test),as.factor(test$status))
```


## Pembuatan model menggunakan decision tree

Pembuatan model decision tree
```{r}
model.tree <- ctree(formula = status~., data = train)
```

Memprediksi data train
```{r}
pred.tree.train <- predict(object = model.tree,newdata = train)
```

Mengevaluasi model terhadap data train
```{r}
confusionMatrix(as.factor(pred.tree.train), as.factor(train$status))
```

Memprediksi data test
```{r}
pred.tree.test <- predict(object = model.tree,newdata = test)
```

Mengevaluasi model terhadap data test
```{r}
confusionMatrix(as.factor(pred.tree.test), as.factor(test$status))
```




