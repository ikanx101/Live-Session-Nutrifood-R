---
title: "Materi Regresi Linear"
author: "Lenny M. Wibisana"
date: "11 September 2020"
output: 
  github_document:
    pandoc_args: --webtex
---

```{r setup, include=FALSE}
setwd("~/Documents/Live-Session-Nutrifood-R/R Training in Class Session/Materinya Lenny")
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
```

# Perhatian _Trainees_

Regresi linear itu mengharusnya data predictor dan target berbentuk numerik. Regresi adalah termasuk _unsupervised learning_.

# Data Preparation

## Load library yang digunakan
```{r}
library(dplyr)
library(tidyverse)
library(GGally)
library(MASS)
library(MLmetrics)
library(lmtest)
library(car)
library(caret)
```

## Read data
```{r}
# read data csv crime, dan beri nama datasetnya `crime`
crime = read.csv("crime.csv")
```

```{r}
# tampilkan 6 data awal dari dataset crime
head(crime,6)
```


Hilangkan kolom X dan mengganti nama kolom dari data agar lebih mudah dipahami
```{r}
crime = 
  crime %>% 
  mutate(X = NULL)

names(crime) <- c("percent_m", "is_south", "mean_education", "police_exp60", "police_exp59", "labour_participation", "m_per1000f", "state_pop", "nonwhites_per1000", "unemploy_m24", "unemploy_m39", "gdp", "inequality", "prob_prison", "time_prison", "crime_rate")

# tampilkan kembali 6 data awal dari dataset yang nama variabelnya sudah diganti
head(crime,6)

# investigasi data
str(crime)
```


Variabel yang ada pada data crime adalah sebagai berikut:
- `percent_m`: percentage of males aged 14-24
- `is_south`: whether it is in a Southern state. 1 for Yes, 0 for No.
- `mean_education`: mean years of schooling
- `police_exp60`: police expenditure in 1960
- `police_exp59`: police expenditure in 1959
- `labour_participation`: labour force participation rate
- `m_per1000f`: number of males per 1000 females
- `state_pop`: state population
- `nonwhites_per1000`: number of non-whites resident per 1000 people
- `unemploy_m24`: unemployment rate of urban males aged 14-24
- `unemploy_m39`: unemployment rate of urban males aged 35-39
- `gdp`: gross domestic product per head
- `inequality`: income inequality
- `prob_prison`: probability of imprisonment
- `time_prison`: average time served in prisons
- `crime_rate`: crime rate in an unspecified category


# Exploratory data analysis

variabel target yang diamati adalah `inequality`

Lihat nilai sebaran data `inequality` yang menjadi target variabel dalam pembahasan kali ini.
```{r}
# buat histogram untuk melihat sebaran data
hist(crime$inequality)

# bisa juga dengan ggplot2
crime %>% 
  ggplot(aes(inequality)) +
  geom_histogram() +
  labs(title = "Histogram dengan ggplot2")
```


Cek korelasi tiap variabel dengan `ggcor`
```{r}
ggcorr(crime, hjust = 1, label = T)
```

> Dari hasil korelasi, variabel yg memiliki korelasi tertinggi dengan variabel target `inequality` adalah variabel ... dan ...


# Membuat model regresi

1. Buat model linear untuk memprediksi inequality berdasarkan gdp
```{r}
model_crime1 = lm(inequality~gdp, crime)

# lihat bentuk modelnya
summary(model_crime1)
```

Maka formulanya adalah:

$$inequality=-0.36551*gdp+386.03058$$

> Setiap kenaikan 1 gdp akan memberikan kontribusi pengurangan 0.36551 terhadap inequality.

Nilai _R-Squared_ sebesar 78.15%.

> Artinya `gpd` mampu menjelaskan 78.15% dari informasi variabel `inequality`.

Nilai _p-value_ sebesar $<0.05$.

> Model menunjukkan pengaruh signifikan dari variabel prediktor terhadap variabel target.

Predict nilai inequality menggunakan fungsi predict()
```{r}
pred1 = predict(model_crime1, newdata = data.frame(gdp = crime$gdp)) 
summary(pred1)
```

2. Buat model linear untuk memprediksi inequality berdasarkan gdp dan mean education

```{r}
model_crime2 <- lm(inequality ~ gdp + mean_education, crime) 

# lihat bentuk modelnya
summary(model_crime2)
```

Untuk kasus ini, jika multiple linear regression yang perlu dilihat adalah `Adjusted R-Squared`.

Predict nilai inequality menggunakan fungsi predict()
```{r}
pred2 = predict(model_crime2, 
                newdata = data.frame(gdp = crime$gdp,
                                     mean_education = crime$mean_education)) 
summary(pred2)
```

3. Bandingkan nilai r.squared, adj.r.squared, dan MSE-nya dari kedua model tersebut

R-squared
```{r}
summary(model_crime1)$r.squared
summary(model_crime2)$r.squared
```

Adjusted R-squared
```{r}
summary(model_crime1)$adj.r.squared
summary(model_crime2)$adj.r.squared
```

> Dari nilai adj R squared, yang memiliki nilai adj r-squared terbesar adalah `model_crime2`.


Nilai MSE dari ketiga model tersebut
```{r}
MSE(model_crime1$fitted.values,crime$inequality)
MSE(model_crime2$fitted.values,crime$inequality)
```
> Dari nilai MSE, yang memiliki nilai lebih kecil adalah `model_crime2`.


Melihat summary dari model yang lebih baik
```{r}
summary(model_crime2)
```


5. Manakah model yang terbaik?

Model `model_crime2` karena R-squared terbaik dan MSE terkecil.



# Cek asumsi

## normality of residual
  
  `cek errorny berdistribusi normal atau ngga`

  H0: residual berdistribusi normal
  H1: residual tidak berdistribusi normal

  pvalue < 0.05, tolak H0, residual tidak berdistribusi normal
  
  Kita ingin pvalue > 0.05 agar error berdistribusi normal
  
  
Dari data crime, pertama-tama cek terlebih dahulu sebaran errornya dengan menggunakan histogram
```{r}
hist(model_crime2$residuals)
```

Uji kenormalan errornya dengan uji statistik `shapiro.test`
```{r}
# pengujian statistik untuk normality
shapiro.test(model_crime2$residuals)
```

Kesimpulan : 

> Residual dari `model_crime2` berdistribusi normal.

## linearity check

Cek linearity dengan plot 

```{r}
# melihat plot residual dan fitted values dari model
plot(model_crime2,1)
```

Uji asumsi untuk linearity
H0 : Tidak Linear
H1 : Linear
Mencari p-value < 0.05 agar tolak H0, sehingga kesimpulannya adalah linear

Notes: Bisa cek cor.test untuk variabel-variabel prediktor yang korelasinya mendekati 0 saja
```{r}
cor.test(crime$gdp,crime$inequality)
cor.test(crime$mean_education,crime$inequality)
```

Note:
ketika salah satu variabel prediktor *tidak terpenuhi(p-value > 0.05)*, maka kesimpulannya model yg kita buat tidak linear.

Kesimpulan: 

> Lolos uji linearity!


## uji homoscedascity

Homoscedasticity = error tidak memiliki pola
Heteroscedasticity = errornya berpola
  
H0: model homoscedasticity
H1: model heteroscedasticity
pvalue < alpha, tolak H0
alpha = 0.05
  
Kalau terdapat heteroscedasticity, kemungkinan ada outlier yang harus dibuang

Plot error dan nilai aktualnya
```{r}
plot(model_crime2$residuals,crime$inequality)
```

Uji statistiknya dengan fungsi bptest() dari library lmtest

```{r}
# test statistik untuk cek homoscedasticity
bptest(model_crime2)
```
  
kesimpulan: 

> p-value > 0.05 maka gagal tolak H0, artinya lolos uji Homoscedasticity


## Uji multicollinearity

Kita tidak mau kalau variabel prediktor di model kita itu saling berpengaruh (dependen). Ujinya menggunakan nilai *vif*.
Syaratnya harus < 10.

Cek dengan fungsi `vif()` dari library car untuk mengetahui variabel-variabel mana yang tidak bisa ditoleransi menjadi sebuah prediktor
```{r}
vif(model_crime2)
```

Kesimpulan : no multicollinearity

Ketika **VIF nilainya > 10**, maka harus ada variabel yang dieliminasi atau dilakukan feature engineering (membuat variabel baru dari variabel2 yang sudah ada)

kalau ad VIF yang nilainya > 10, maka harus ada salah 1 variabel yg dihilangkan, atau gabungin variabel yg berkorelasi kuat menjadi 1 variabel baru


---------------------------------------------------------------------------------------------------------------------------------------------

# Tambahan

Feature Selection using Stepwise Regression

Stepwise Regression merupakan salah satu greedy algorithm (akan menghasilkan model yang local optima, bukan global optima)

Terminologi:
Local optima = model yang baik namun belum tentu terbaik
Global optima = model terbaik

Mengevaluasi model stepwise menggunakan nilai AIC (Akaike Information Criterion/ Information Loss), model dengan AIC yang terkecil, itu yang dipilih

Stepwise regression mempunyai 3 metode yaitu: backward, forward, both
*Forward selection* : mengevaluasi model dengan cara menambahkan variabel prediktor sehingga diperoleh model dengan AIC (Akaike Information Criterion) terkecil/R-squared terbesar
(Dari tidak ada prediktor, ditambahkan satu per satu sampai mendapat model yang local optima(**baik tapi belum tentu terbaik**))
*Backward elimination* : mengevaluasi model dengan cara mengurangi variabel prediktor sehingga diperileh model AIC terkecil/R-squared nya besar
(Dari semua prediktor, dieliminasi satu satu untuk mendapat model yang baik, dievaluasi dari nilai AIC)
*Both* :Backward and Forward

```{r}
# model tanpa prediktor
lm.none <- lm(inequality~1, crime)

# model dengan semua prediktor
lm.all <- lm(inequality~., crime)
```

## Stepwise backward
```{r}
crime_back <- step(lm.all, direction = "backward")
summary(crime_back)
```

## Stepwise forward
```{r}
crime_forward <- step(lm.none, scope = list(lower = lm.none, upper = lm.all), direction = "forward")
summary(crime_forward)
```

## Stepwise both
```{r}
crime_both <- step(lm.none, scope = list(lower = lm.none, upper = lm.all), direction = "both")
summary(crime_both)
```

Summary stepwise
```{r}
summary(crime_back)
summary(crime_forward)
summary(crime_both)
```

## Evaluasi model
Perbandingan nilai adjusted r-squared pada ketiga model yang sudah dibuat
```{r}
summary(crime_back)$adj.r.squared
summary(crime_forward)$adj.r.squared
summary(crime_both)$adj.r.squared
```

> nilai adjusted r-squared yang terbesar adalah model `crime_back`


Perbandingan nilai MSE
```{r}
MSE(crime_back$fitted.values, crime$inequality)
MSE(crime_forward$fitted.values, crime$inequality)
MSE(crime_both$fitted.values, crime$inequality)
```
> nilai MSE yang terkecil adalah model `crime_back`
